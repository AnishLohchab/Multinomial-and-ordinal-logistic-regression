{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2faf560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all necessary libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy as scp\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53eb61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset\n",
    "abalone_df = pd.read_csv('abalone.csv') \n",
    "abalone_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423faf71",
   "metadata": {},
   "source": [
    "There are 10 variables of which the first - SEX - will be used as the dependent variable.   \n",
    " Additional Information\n",
    "\n",
    "Predicting the age of abalone from physical measurements.  \n",
    "The age of abalone is determined by cutting the shell through the cone, staining it, \n",
    "and counting the number of rings through a microscope -- a boring and time-consuming task.  \n",
    "Other measurements, which are easier to obtain, are used to predict the age.  \n",
    "Further information, such as weather patterns and location \n",
    "(hence food availability) may be required to solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abalone_sex=abalone_df['Sex'].value_counts()\n",
    "\n",
    "print(Abalone_sex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffef95",
   "metadata": {},
   "source": [
    "Description Of Data: \n",
    "The data is sourced from study of Abalone in Tasmania. \n",
    "It can be found at the UCI Machine Learning Repository. The dataset contains 4,177 observations and 9 variables. \n",
    "\n",
    "SEX = M (male), F (female), I (infant) \n",
    "\n",
    "LENGTH = Longest shell length in mm \n",
    "\n",
    "DIAM = Diameter perpendicular to length in mm \n",
    "\n",
    "HEIGHT = Height perpendicular to length and diameter in mm \n",
    "\n",
    "WHOLE = Whole weight of abalone in grams \n",
    "\n",
    "SHUCK = Shucked weight of meat in grams \n",
    "\n",
    "VISCERA = Viscera weight in grams \n",
    "\n",
    "SHELL = Shell weight after drying in grams \n",
    "\n",
    "RINGS = Age (+1.5 gives the age in years) \n",
    "\n",
    "\n",
    "\n",
    "We are now ready to partition the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca908e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test datasets\n",
    "#CLASS was recoded into SIZE_CLASS to change from string to integer\n",
    "#CLASS needs to be dropped\n",
    "X = abalone_df.drop(['Sex'], axis=1) \n",
    "y = abalone_df['Sex']\n",
    "\n",
    "print(list(X.columns.values)) \n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.20, random_state = 5)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676725db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegression(random_state=0, multi_class='multinomial', penalty=None, solver='newton-cg').fit(X_train, y_train)\n",
    "\n",
    "preds = model1.predict(X_test)\n",
    "\n",
    "params = model1.get_params()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c4094",
   "metadata": {},
   "source": [
    "Intercept And Coefficients: \n",
    "The intercept and coefficients are stored in model1.intercept and model1. \n",
    "coef_ respectively. Here we need to spend a bit of time, \n",
    "because the output of Sci-Kit Learn is different from what we may expect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b4f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print model parameters\n",
    "print('Intercept: \\n', model1.intercept_)\n",
    "print('Coefficients: \\n', model1.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5644b994",
   "metadata": {},
   "source": [
    "The first array contains three intercepts and the second  array contains three sets of regression coefficients.  \n",
    "This is different from what we may be used to in SAS and R.  \n",
    "In fact, the sklearn based output is different from the statsmodel version \n",
    "(A discussion of Multinomial Logistic Regression with statsmodels is available below). \n",
    "\n",
    "\n",
    "In this solution, there is an equation for each class. \n",
    "These act as independent binary logistic regression models. \n",
    "The actual output is log(p(y=c)/1 - p(y=c)), which are multinomial logit coefficients, \n",
    "hence the three equations.  After exponentiating each regressor coefficient, we in fact get odds ratios. \n",
    "The interpretation of the coefficients is for a single unit change in the predictor variable, \n",
    "the log of odds will change by a factor indicated by the beta coefficient, given that all other \n",
    "variables are held constant.  Log of odds is not really meaningful, so exponentiating the output gets a \n",
    "slightly more user friendly output: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce84af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate odds ratio estimates\n",
    "import numpy as np\n",
    "np.exp(model1.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76276d08",
   "metadata": {},
   "source": [
    "Statsmodels:\n",
    "Notice that the statsmodels output is very different from that of sklearn.  \n",
    "In this case, there are K-1, in this case two equations, which show coefficients against a reference group. \n",
    "In the abalone example, the reference group was chosen to be female. \n",
    "The coefficients represent the log of ratios between two probabilities: \n",
    "the probability of belonging to a group of interest vs. the probability of belonging to the reference group.  \n",
    "In the abalone example, the reference group was female, therefore the equation below represents the first set of \n",
    "coefficients marked as SEX=Infant.  \n",
    "Note that there are two sets of coefficients, one marked as Infant and  the second marked as Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use statsmodels to assess variables\n",
    "\n",
    "logit_model=sm.MNLogit(y_train,sm.add_constant(X_train))\n",
    "logit_model\n",
    "result=logit_model.fit()\n",
    "stats1=result.summary()\n",
    "stats2=result.summary2()\n",
    "print(stats1)\n",
    "print(stats2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941e7ebf",
   "metadata": {},
   "source": [
    "Accuracy:\n",
    "Assessing the accuracy of the model is not difficult but errors at the different levels act as a compounding problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0823f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit learn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c910f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a confusion matrix y_test as first argument and the preds as second argument \n",
    "confusion_matrix(y_test, preds)\n",
    "\n",
    "#transform confusion matrix into array the matrix is stored in a vaiable called confmtrx\n",
    "confmtrx = np.array(confusion_matrix(y_test, preds))\n",
    "\n",
    "# Create DataFrame from confmtrx array  rows for test: Male, Female, Infant designation as index \n",
    "# columns for preds: male, predicted_female, predicted_infant as column\n",
    "\n",
    "pd.DataFrame(confmtrx, index=['Female','Infant', 'Male'],\n",
    "columns=['predicted_Female', 'predicted_Infant', 'predicted_Male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy statistics\n",
    "\n",
    "print('Accuracy Score:', metrics.accuracy_score(y_test, preds))  \n",
    "\n",
    "#Create classification report\n",
    "class_report=classification_report(y_test, preds)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc23c67",
   "metadata": {},
   "source": [
    "The accuracy of this model is poor with only 55% of predictions being correct. \n",
    "The precision and recall of female and male abalone is very concerning as well.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c701cf",
   "metadata": {},
   "source": [
    "Task1: Load the iris dataset by using seaborn library and fit multinomial logistic regression  model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bee1c8",
   "metadata": {},
   "source": [
    "# ordinal logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aea800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_diam = pd.read_csv('diamonds.csv')\n",
    "data_diam.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e7f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diam['cut'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666190cd",
   "metadata": {},
   "source": [
    "Data preprocessing \n",
    "Here we can see that we have three variables in the object form and in this article we are dealing with the cut variable. \n",
    "To work with the ordinal models from statsmodel we are required to convert this target variable into a categorical ordered form that can be done using the following lines of codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f0a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "cat_type = CategoricalDtype(categories=['Fair', 'Good', 'Ideal', 'Very Good', 'Premium'], ordered=True)\n",
    "\n",
    "data_diam[\"cut\"] = data_diam[\"cut\"].astype(cat_type)\n",
    "\n",
    "data_diam['cut'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a2b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now in the data, we have variables X, Y, and Z that represent the height, width, and depth of the diamond. \n",
    "# By multiplying them we can calculate the volume of the diamonds. Let’s calculate the volume.\n",
    "\n",
    "data_diam['volume'] = data_diam['x'] * data_diam['y'] * data_diam['z']\n",
    "\n",
    "data_diam.drop(['x','y','z'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ace45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we have multiplied the columns X, Y, and Z and dropped them from the data.\n",
    "# Let’s plot the data to know about the distribution.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "plt.figure(figsize=[24,24])\n",
    " \n",
    "plt.subplot(221)\n",
    "plt.hist(data_diam['carat'],bins=20,color='b')\n",
    "plt.xlabel('Weight')\n",
    "plt.title('Distribution by Weight')\n",
    " \n",
    "plt.subplot(222)\n",
    "plt.hist(data_diam['depth'],bins=20,color='r')\n",
    "plt.xlabel('Diamond Depth')\n",
    "plt.title('Distribution by Depth')\n",
    " \n",
    "plt.subplot(223)\n",
    "plt.hist(data_diam['price'],bins=20,color='g')\n",
    "plt.xlabel('Price')\n",
    "plt.title('Distribution by Price')\n",
    " \n",
    "plt.subplot(224)\n",
    "plt.hist(data_diam['volume'],bins=20,color='m')\n",
    "plt.xlabel('Volume')\n",
    "plt.title('Distribution by Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dfce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered probit model\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "mod_prob = OrderedModel(data_diam['cut'],\n",
    "                        data_diam[['volume', 'price', 'carat']],\n",
    "                        distr='probit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the above lines of codes, we have called the OrderedModel module that holds the function for the \n",
    "# ordinal regression and instantiates an Ordered probit model while taking the cut variable as our target and \n",
    "# volume, price, and carat as independent variables.\n",
    "# We can fit and check the summary of the model using the following lines of codes:\n",
    "\n",
    "res_prob = mod_prob.fit(method='bfgs')\n",
    "res_prob.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered logit regression \n",
    "# Codes for this model are also similar to the above codes except for one thing we need to change is the parameter distr. In the above, we can see it is set as probit and needs to change in logit. \n",
    "\n",
    "mod_prob = OrderedModel(data_diam['cut'],\n",
    "                        data_diam[['volume', 'price', 'carat']],\n",
    "                        distr='logit')\n",
    " \n",
    "res_log = mod_prob.fit(method='bfgs')\n",
    "res_log.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cacab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can make the prediction from the model.\n",
    "\n",
    "predicted = res_log.model.predict(res_log.params, exog=data_diam[['volume', 'price', 'carat']])\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d3c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
